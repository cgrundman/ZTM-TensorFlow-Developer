{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNor6+15lSDsHV4vRm75C2P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgrundman/ZTM-TensorFlow-Developer/blob/main/04_transfer_learning_part_1_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow Part 1: Feature Extraction\n",
        "\n",
        "Transfer learning is leveraging a working model's existing architecture and learned patters for our own problem.\n",
        "\n",
        "There are two main benefits:\n",
        "1.   Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2.   Can leverage a working neural network architecture which has already learned patters on similar data to our own, then we can adapt those patterns to our own data."
      ],
      "metadata": {
        "id": "xXdhaWboDdoK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ryHOhQldrUG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b6a7325-3c9f-47d9-87e0-41a90435d8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jun 22 09:43:29 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Are we using a GPU?\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and becoming one with the data"
      ],
      "metadata": {
        "id": "ExWKpPuwFSgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data (10% of 10 food classes from Food101)\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P83HdozKFabC",
        "outputId": "f3600f90-7382-4b75-c312-a81574137753"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-22 09:43:30--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.31.207, 142.251.18.207, 142.250.153.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.31.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  38.1MB/s    in 4.8s    \n",
            "\n",
            "2024-06-22 09:43:35 (33.7 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data directory an list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4d_FA_dF8wI",
        "outputId": "563852ca-0807-4e38-fcab-edd10b8b10b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data loader (preparing the data)\n",
        "\n",
        "We'll use the ``ImageDataGenerator`` class to load in our images in batches."
      ],
      "metadata": {
        "id": "O2BJqCkDHeug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print (\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMAGE_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "print (\"Testing images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMAGE_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvEfuSAvHtSW",
        "outputId": "443c0fd3-676b-42f5-aba1-9b9ba5e4e433"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run whilst our model trains)\n",
        "\n",
        "Callbacks are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbcks:\n",
        "\n",
        "* Tracking experiements with the TensorBoard callback\n",
        "* Model checkpoint with the ModelCheckpoint callback\n",
        "* Stopping a model from training (before it trains too long and overfits) with the EarlyStopping callback"
      ],
      "metadata": {
        "id": "Ko6CbMrAI9bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorBoard callback (functionized because we need to create a new one for each model)\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "f_K3_tByWBiX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "In the past we've used TensorFlow to create our own models layer by layer from scratch.\n",
        "\n",
        "Now we're going to do a similar process, except the majority of our model's layers are going to come from TensorFlow Hub.\n",
        "\n",
        "We can access pretrained models on: https://tfhub.dev/\n",
        "\n",
        "The TensorFlow Hub page has been moved to kaggle, so we will look at the following URLs for the models that we will compare:\n",
        "\n",
        "* \"https://www.kaggle.com/models/google/resnet-v2/TensorFlow2/50-feature-vector/2\"\n",
        "* \"https://www.kaggle.com/models/tensorflow/efficientnet/TensorFlow2/b0-feature-vector/1\""
      ],
      "metadata": {
        "id": "AVMOmXhDYePA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the following two models\n",
        "resnet_url = \"https://www.kaggle.com/models/google/resnet-v2/TensorFlow2/50-feature-vector/2\"\n",
        "\n",
        "efficientnet_url = \"https://www.kaggle.com/models/tensorflow/efficientnet/TensorFlow2/b0-feature-vector/1\""
      ],
      "metadata": {
        "id": "Cvv-LtvMYkDi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "z9qgJoPGc0s3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a create_model() function to create a model from a URL\n",
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"\n",
        "  Takes a Kaggle URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "    model_url (str): A TensorFlowHub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in the output layer,\n",
        "      should be equal to the number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as the feature extractor\n",
        "    layer and Dense output layer with num_classes output neurons.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False, # Freeze the already earned patterns\n",
        "                                           name=\"feature_extraction_layer\",\n",
        "                                           input_shape=IMAGE_SHAPE+(3,))\n",
        "\n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "sAL5A1yWc_ak"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing ResNet TensorFlow Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "P4VvAk0GewaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ResNet model\n",
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes=train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "id": "2iyEfhDEe_q6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_hTxJiefMeq",
        "outputId": "1ee01b68-c23d-40b2-c6cc-26954ad82637"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (  (None, 2048)              23564800  \n",
            " KerasLayer)                                                     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23585290 (89.97 MB)\n",
            "Trainable params: 20490 (80.04 KB)\n",
            "Non-trainable params: 23564800 (89.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile our ResNet model\n",
        "resnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "rW_SkZB7fisU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's fit our ResNet model to the data (10 percent of the 10 classes)\n",
        "\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                         experiment_name=\"resnet50V2\")\n",
        "                                  ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybd4k2Hcf49Z",
        "outputId": "548ce4ba-83d7-483f-d862-f6a0c9ecdd2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/resnet50V2/20240622-103750\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 23s 619ms/step - loss: 1.8586 - accuracy: 0.3880 - val_loss: 1.1845 - val_accuracy: 0.6060\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 13s 541ms/step - loss: 0.8898 - accuracy: 0.7213 - val_loss: 0.9041 - val_accuracy: 0.7036\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 11s 458ms/step - loss: 0.6188 - accuracy: 0.8147 - val_loss: 0.7594 - val_accuracy: 0.7524\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 11s 461ms/step - loss: 0.4707 - accuracy: 0.8813 - val_loss: 0.7047 - val_accuracy: 0.7692\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 11s 464ms/step - loss: 0.3794 - accuracy: 0.9080 - val_loss: 0.6886 - val_accuracy: 0.7696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qbed3wVIhhnU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}